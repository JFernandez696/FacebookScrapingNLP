{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Julio_Fernandez.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsMihxTmQ9Rq"
      },
      "source": [
        "# **Examen 1: Procesamiento de Lenguaje Natural**\n",
        "# Maestría Ciencias de la Computación UNI\n",
        "\n",
        "\n",
        "Indicaciones: \n",
        "* Desarrolle cada pregunta en el orden correspondiente.\n",
        "* Pueden utilizar cualquier material ya sea de clase o internet.\n",
        "* Día de Entrega : Jueves 15 de Junio a las 10pm\n",
        "* **NO** va haber más tiempo para subir su archivo, considerar los minutos que demora en subir su documento al buzón.\n",
        "* Subir al buzón el notebook desarrollado en el siguiente formato: nombre_apellido.ipynb\n",
        "* Evaluación individual, si se detecta **plagio** se **ELIMINARÁ** todos los exámenes involucrados.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beazp5tdSQ54"
      },
      "source": [
        "# Introducción : \n",
        "\n",
        "El objetivo del ejercicio es obtener la **mayor cantidad** de noticias \n",
        "de las siguiente fuente.\n",
        "\n",
        "https://www.facebook.com/prensachalaca\n",
        "\n",
        "Deberá realizar lo siguiente: (10ptos)\n",
        "\n",
        "1.   Recuperación de los datos, Dataframe con las siguientes columnas CuerpoNoticia, TipoNoticia , Comentarios\n",
        "2.   Pre-procesamiento de los comentarios, juntar todos los textos de los comentarios en una columna (prepComentarios) y aplicar pre-procesamiento.\n",
        "3. Realizar una nube de palabras con las frecuencias de las palabras en todas las entradas de prepComentarios.\n",
        "4. Crear un modelo de lenguaje estadistico usand los comentarios procesados anteriomente.\n",
        "\n",
        "Luego de obtener el modelo, deberá generar 5 oraciones. (5ptos)\n",
        "\n",
        "Comentar sus resultados y plantear una hipotesis del porque los resultados podrían variar. (5ptos)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRoOh5TrQ7ip"
      },
      "source": [
        "#Agregar las librerias a utilizar\n",
        "#....\n",
        "import unicodedata\n",
        "#...."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZvKinN2eIHP"
      },
      "source": [
        "# para normalizar el texto a unicode utilice lo siguiente\n",
        "text_normalized= unicodedata.normalize(\"NFKD\", variable_texto_sin_normalizar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLOG0unPZlPu",
        "outputId": "f5451e78-72c6-4ba6-ddf8-9ef8b50aba6a"
      },
      "source": [
        "import requests\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.166 Safari/537.36\",\n",
        "    \"Accept-Encoding\": \"*\",\n",
        "    \"Connection\": \"keep-alive\"\n",
        "}\n",
        "\n",
        "SESSION = requests.session()\n",
        "SESSION.cookies.clear()\n",
        "\n",
        "url = \"https://www.facebook.com/prensachalaca/\"\n",
        "print(\"Requesting URL:\", url)\n",
        "response = requests.get(url, headers=HEADERS)\n",
        "print(\"Response code:\", response.status_code)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requesting URL: https://www.facebook.com/prensachalaca/\n",
            "Response code: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desarrollo\n"
      ],
      "metadata": {
        "id": "tlq5r8xF09KJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_68Yb7_I1fAN",
        "outputId": "85f5a10d-4002-4677-c453-422113cf3f26"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.1.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 26.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facebook_scraper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owXfiYn01BGl",
        "outputId": "7d794fa2-667d-4c69-d490-384407a2189b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: facebook_scraper in /usr/local/lib/python3.7/dist-packages (0.2.56)\n",
            "Requirement already satisfied: dateparser<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from facebook_scraper) (1.1.1)\n",
            "Requirement already satisfied: requests-html<0.11.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from facebook_scraper) (0.10.0)\n",
            "Requirement already satisfied: demjson3<4.0.0,>=3.0.5 in /usr/local/lib/python3.7/dist-packages (from facebook_scraper) (3.0.5)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,<2022.3.15 in /usr/local/lib/python3.7/dist-packages (from dateparser<2.0.0,>=1.0.0->facebook_scraper) (2022.3.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser<2.0.0,>=1.0.0->facebook_scraper) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser<2.0.0,>=1.0.0->facebook_scraper) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser<2.0.0,>=1.0.0->facebook_scraper) (2022.1)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (0.1.11)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.0.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (0.0.1)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.7/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.19.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.23.0)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.7/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.22.0)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.7/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.4.3)\n",
            "Requirement already satisfied: certifi>=2021 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.25.11)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.11.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.64.0)\n",
            "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (8.2.2)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (10.3)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.4.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.6.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.2.6)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser<2.0.0,>=1.0.0->facebook_scraper) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (3.8.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from facebook_scraper import get_posts\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "metadata": {
        "id": "7nubFE_B1BD9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posts = []\n",
        "# Obtenemos la información de las publicaciones\n",
        "for post in get_posts('prensachalaca', pages=50):\n",
        "  posts.append(post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ejaD59fR1BJt",
        "outputId": "afc77e6f-90d0-4e41-b895-9f792ada9f04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LoginRequired",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLoginRequired\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-98bc8e48a312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mposts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Obtenemos la información de las publicaciones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_posts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prensachalaca'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mposts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/facebook_scraper/facebook_scraper.py\u001b[0m in \u001b[0;36m_generic_get_posts\u001b[0;34m(self, extract_post_fn, iter_pages_fn, page_limit, options, remove_source, latest_date, max_past_limit, **kwargs)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting to iterate pages\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_pages_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting posts from page %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mpost_element\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/facebook_scraper/page_iterators.py\u001b[0m in \u001b[0;36mgeneric_iter_pages\u001b[0;34m(start_url, page_parser_cls, request_fn, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Requesting page from: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/facebook_scraper/facebook_scraper.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 ):\n\u001b[1;32m    890\u001b[0m                     raise exceptions.LoginRequired(\n\u001b[0;32m--> 891\u001b[0;31m                         \u001b[0;34m\"A login (cookies) is required to see this page\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                     )\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLoginRequired\u001b[0m: A login (cookies) is required to see this page"
          ]
        }
      ]
    }
  ]
}